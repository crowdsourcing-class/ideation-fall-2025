# Memory Mosaic

## Team Members
- Ani Petrosyan (anipet@seas.upenn.edu)
- Dea Rrozhani (rrozhani@seas.upenn.edu)
- Lakshman Swaminathan (lakshman.swaminathan1@gmail.com)
- Liam Dodds (wdodds@sas.upenn.edu)

## Project Resources
- **Video Presentation**: https://drive.google.com/file/d/1TZ-fzSye4L3oVTWDpE-PIVTa_tj3MBhv/view
- **Website**: Developed web application
- **Report**: 296606355_Memory_Mosaic.pdf

## Project Synopsis
Memory Mosaic is a collaborative platform that allows groups of users to upload photos from shared events and collectively build visual memory boards. The platform centralizes personal memories tied to significant events that are typically scattered across different digital platforms. Users can upload photos and vote on them to create curated collections of shared experiences.

## How It Uses the Crowd
The crowd contributes through:
- **Photo Collection**: Users upload photos from shared events
- **Curation**: Up-voting and down-voting photos to surface best content
- **Collaborative Memory Building**: Groups collectively create visual narratives
- **Real Event Data**: Successfully collected photos from actual campus groups

## Strengths
- **Professional Implementation**: Substantial, professional-looking web app with polished interface
- **Strong Technical Architecture**: Well-thought-out NoSQL database choice and system design
- **Quality Control Integration**: Good use of OpenAI moderation API for content filtering
- **Polished Presentation**: Video came across as professional startup pitch
- **Unique Concept**: Addresses real need for centralizing event memories
- **Real-World Testing**: Successfully tested with actual campus group photos

## Weaknesses
- **Limited Crowd Utilization**: Narrow use of crowd (only upload and vote) - missed opportunities for:
  - Collaborative storytelling and annotation
  - Photo categorization (ceremony, reception, etc.)
  - Friend tagging and personalization
  - Photo editing and touch-ups
  - Creating sub-events within main events
- **Unimpressive Output**: Final mosaic appeared as simple photo stack, similar to existing products
- **Simulated Engagement**: Upvotes were provided by team rather than organic crowd participation
- **Under-developed Features**: Limited incentive mechanisms and comparison of QC strategies
- **Scalability Concerns**: Disagreement with team's scaling estimates for votes per photo

## Course Concept Alignment
The project demonstrates:
- **High understanding** of quality control, incentives, and scaling
- **Adequate understanding** of crowd utilization, ethics, and aggregation
- **Inadequate understanding** of creative crowd capabilities and sophisticated aggregation
- Good technical implementation but limited crowdsourcing innovation

## Recommendations for Improvement
1. Expand crowd participation:
   - Enable collaborative storytelling and photo annotation
   - Allow crowd to create event timelines and narratives
   - Implement friend tagging and social features
2. Enhance output products:
   - Create more sophisticated visual outputs beyond simple stacks
   - Generate event highlights and summaries
   - Produce shareable memory books or videos
3. Improve content organization:
   - Add sub-event categorization
   - Enable temporal organization
   - Create themed collections
4. Address safety concerns:
   - Strengthen policies for harassment and inappropriate content
   - Implement reporting mechanisms
   - Consider privacy controls for sensitive events