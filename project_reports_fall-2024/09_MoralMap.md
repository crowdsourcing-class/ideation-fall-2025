# MoralMap

## Team Members
- Anushka Levaku (alevaku@seas.upenn.edu)
- Ben Tausner (btausner@seas.upenn.edu)
- Samuel Tausner (stausner@sas.upenn.edu)
- Mantas Viazmitinas (mantasv@seas.upenn.edu)
- Marc Vaz (vazmarc@seas.upenn.edu)
- Grant Wells (gawells@seas.upenn.edu)

## Project Resources
- **Video Presentation**: https://drive.google.com/file/d/1rtRMBXoYhIRCXGMcAgpbadhTshJidngu/view
- **Website**: Developed platform (may not have continued functionality)
- **Report**: 296657453_MoralMap.pdf

## Project Synopsis
MoralMap collects data about moral decisions from participants along with their demographic backgrounds, allowing analysis of how factors like religion, geography, and other demographics affect perception of ethical issues. The project aims to harvest valuable human moral judgments that cannot be automated or simulated, creating a dataset that becomes increasingly valuable as AI systems proliferate.

## How It Uses the Crowd
The crowd contributes through:
- **Moral Judgments**: Providing opinions on ethical dilemmas
- **Demographic Data**: Sharing background information for correlation analysis
- **Unique Human Input**: Creating data that cannot be automated or faked
- **Cross-Demographic Insights**: Enabling analysis beyond typical demographic boundaries

## Strengths
- **Valuable Data Collection**: Harvests irreplaceable human moral perceptions
- **Timely Relevance**: Increasingly important as AI cannot authentically simulate moral judgments
- **Good Technical Choices**: Custom database for reduced friction and privacy
- **Strong Self-Awareness**: Excellent understanding of project strengths and limitations
- **Quality Video**: Excellent presentation highlighting challenges and solutions
- **First-Class Data**: Produces information only obtainable from human crowds

## Weaknesses
- **Fatal Incentive Flaw**: 
  - No sustainable incentive mechanism beyond class participation
  - Project cannot outlive the course without incentives
  - No value returned to participants
- **Biased Question Framing**:
  - Binary choices flatten complex moral issues
  - Recreates existing polarization rather than capturing nuance
  - Example: "Should abortion be legal in all cases?" forces oversimplified positions
- **Missing Features**:
  - No live aggregation interface
  - No debiasing of biased sample (geographic, demographic)
  - Susceptible to data manipulation with anonymous inputs
- **Incomplete Implementation**: 
  - Aggregation not built into platform
  - No ongoing statistics or community feedback

## Course Concept Alignment
The project demonstrates:
- **High understanding** of crowd value and what crowds provide
- **Adequate understanding** of crowd dynamics, ethics, quality control
- **Inadequate understanding** of incentives and scaling
- Strong conceptual foundation but critical implementation gaps

## Recommendations for Improvement
1. **Fix Incentive Structure**:
   - Show live statistics to create curiosity value
   - Implement "wisdom of crowd" feedback showing majority opinions
   - Add social good messaging
   - Create shareable results
2. **Redesign Questions for Nuance**:
   - Replace binary with spectrum questions
   - Add contextual scenarios
   - Include value prioritization exercises
   - Example: 20-question nuanced approach for complex topics
3. **Build Live Platform**:
   - Implement real-time aggregation
   - Create interactive dashboards
   - Add demographic filtering views
   - Enable ongoing participation
4. **Address Data Quality**:
   - Implement sample debiasing
   - Add verification mechanisms
   - Prevent gaming through rate limiting
   - Consider verified accounts for sensitive topics
5. **Enhance Analysis**:
   - Build resampling for representative results
   - Add confidence intervals
   - Create predictive models
   - Export research-grade datasets